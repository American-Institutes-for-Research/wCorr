<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>wCorr Formulas • wCorr</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="wCorr Formulas">
<meta property="og:description" content="wCorr">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">wCorr</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.9.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/wCorrArguments.html">wCorr Arguments</a>
    </li>
    <li>
      <a href="../articles/wCorrFormulas.html">wCorr Formulas</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/ahmademad/wCorr/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="wCorrFormulas_files/header-attrs-2.7/header-attrs.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>wCorr Formulas</h1>
                        <h4 class="author">Paul Bailey, Ahmad Emad, Ting Zhang, Qingshu Xie</h4>
            
            <h4 class="date">2021-05-18</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/ahmademad/wCorr/blob/master/vignettes/wCorrFormulas.Rmd"><code>vignettes/wCorrFormulas.Rmd</code></a></small>
      <div class="hidden name"><code>wCorrFormulas.Rmd</code></div>

    </div>

    
    
<p>The wCorr package can be used to calculate Pearson, Spearman, polyserial, and polychoric correlations, in weighted or unweighted form.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> The package implements the tetrachoric correlation as a specific case of the polychoric correlation and biserial correlation as a specific case of the polyserial correlation. When weights are used, the correlation coefficients are calculated with so called sample weights or inverse probability weights.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a></p>
<p>This vignette introduces the methodology used in the wCorr package for computing the Pearson, Spearman, polyserial, and polychoric correlations, with and without weights applied. For the polyserial and polychoric correlations, the coefficient is estimated using a numerical likelihood maximization.</p>
<p>The weighted (and unweighted) likelihood functions are presented. Then simulation evidence is presented to show correctness of the methods, including an examination of the bias and consistency. This is done separately for unweighted and weighted correlations.</p>
<p>Numerical simulations are used to show:</p>
<ul>
<li>The bias of the methods as a function of the true correlation coefficient (<span class="math inline">\(\rho\)</span>) and the number of observations (<span class="math inline">\(n\)</span>) in the unweighted and weighted cases; and</li>
<li>The accuracy [measured with root mean squared error (RMSE) and mean absolute deviation (MAD)] of the methods as a function of <span class="math inline">\(\rho\)</span> and <span class="math inline">\(n\)</span> in the unweighted and weighed cases.</li>
</ul>
<p>Note that here <em>bias</em> is used for the mean difference between true correlation and estimated correlation.</p>
<p>The <em>wCorr Arguments</em> vignette describes the effects the <code>ML</code> and <code>fast</code> arguments have on computation and gives examples of calls to wCorr.</p>
<div id="specification-of-estimation-formulas" class="section level1">
<h1 class="hasAnchor">
<a href="#specification-of-estimation-formulas" class="anchor"></a>Specification of estimation formulas</h1>
<p>Here we focus on specification of the correlation coefficients between two vectors of random variables that are jointly bivariate normal. We call the two vectors <strong><em>X</em></strong> and <strong><em>Y</em></strong>. The <span class="math inline">\(i^{th}\)</span> members of the vectors are then called <span class="math inline">\(x_i\)</span> and <span class="math inline">\(y_i\)</span>.</p>
<div id="formulas-for-pearson-correlations-with-and-without-weights" class="section level2">
<h2 class="hasAnchor">
<a href="#formulas-for-pearson-correlations-with-and-without-weights" class="anchor"></a>Formulas for Pearson correlations with and without weights</h2>
<p>The weighted Pearson correlation is computed using the formula <span class="math display">\[r_{Pearson}=\frac{\sum_{i=1}^n \left[ w_i (x_i-\bar{x})(y_i-\bar{y}) \right]}{\sqrt{\sum_{i=1}^n \left( w_i  (x_i-\bar{x})^2 \right)\sum_{i=1}^n \left( w_i  (y_i-\bar{y})^2 \right) }} \]</span></p>
<p>where <span class="math inline">\(w_i\)</span> is the weights, <span class="math inline">\(\bar{x}\)</span> is the weighted mean of the <strong><em>X</em></strong> variable (<span class="math inline">\(\bar{x}=\frac{1}{\sum_{i=1}^n w_i}\sum_{i=1}^n w_i x_i\)</span>), <span class="math inline">\(\bar{y}\)</span> is the weighted mean of the <strong><em>Y</em></strong> variable (<span class="math inline">\(\bar{y}=\frac{1}{\sum_{i=1}^n w_i}\sum_{i=1}^n w_i y_i\)</span>), and <span class="math inline">\(n\)</span> is the number of elements in <strong><em>X</em></strong> and <strong><em>Y</em></strong>.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<p>The unweighted Pearson correlation is calculated by setting all of the weights to one.</p>
</div>
<div id="formulas-for-spearman-correlations-with-and-without-weights" class="section level2">
<h2 class="hasAnchor">
<a href="#formulas-for-spearman-correlations-with-and-without-weights" class="anchor"></a>Formulas for Spearman correlations with and without weights</h2>
<p>For the Spearman correlation coefficient the unweighted coefficient is calculated by ranking the data and then using those ranks to calculate the Pearson correlation coefficient–so the ranks stand in for the <strong><em>X</em></strong> and <strong><em>Y</em></strong> data. Again, similar to the Pearson, for the unweighted case the weights are all set to one.</p>
<p>For the unweighted case the highest rank receives a value of 1 and the second highest 2, and so on down to the <span class="math inline">\(n\)</span>th value. In addition, when data are ranked, ties must be handled in some way. The chosen method is to use the average of all tied ranks. For example, if the second and third rank units are tied then both units would receive a rank of 2.5 (the average of 2 and 3).</p>
<p>For the weighted case there is no commonly accepted weighted Spearman correlation coefficient. Stata does not estimate a weighted Spearman and SAS does not document their methodology in either of the corr or freq procedures.</p>
<p>The weighted case presents two issues. First, the ranks must be calculated. Second, the correlation coefficient must be calculated.</p>
<p>Calculating the weighted rank for an individual level is done via two terms. For the <span class="math inline">\(j\)</span>th element the rank is</p>
<p><span class="math display">\[rank_j = a_j + b_j\]</span></p>
<p>The first term <span class="math inline">\(a_j\)</span> is the sum of all weights <strong><em>W</em></strong> less than or equal to this value of the outcome being ranked (<span class="math inline">\(\xi_j\)</span>)</p>
<p><span class="math display">\[a_j = \sum_{i=1}^n w_i \mathbf{1}\left( \xi_i &lt; \xi_j \right)\]</span></p>
<p>where <span class="math inline">\(\mathbf{1}(\cdot)\)</span> is the indicator function that is one when the condition is true and 0 when the condition is false, <span class="math inline">\(w_i\)</span> is the <span class="math inline">\(i\)</span>th weight and <span class="math inline">\(\xi_i\)</span> and <span class="math inline">\(\xi_j\)</span> are the <span class="math inline">\(i\)</span>th and <span class="math inline">\(j\)</span>th value of the vector being ranked, respectively.</p>
<p>The term <span class="math inline">\(b_j\)</span> then deals with ties. When there are ties each unit receives the mean rank for all of the tied units. When the weights are all one and there are <span class="math inline">\(n\)</span> tied units the vector of tied ranks would be <span class="math inline">\(\mathbf{v}=\left(a_j+1, a_j+2, \dots, a_j+n \right)\)</span>. The mean of this vector (here called <span class="math inline">\(rank^1\)</span> to indicate it is a specific case of <span class="math inline">\(rank\)</span> when the weights are all one) is then</p>
<p><span class="math display">\[rank_j^1=\frac{1}{n}  \sum_{i=1}^n \left(a_j + i \right)\]</span> <span class="math display">\[=\frac{1}{n} \left( n a_j +  \frac{n(n+1)}{2}  \right)\]</span> <span class="math display">\[=a_j +  \frac{n+1}{2}\]</span></p>
<p>thus</p>
<p><span class="math display">\[b_j^1=\frac{n+1}{2}\]</span></p>
<p>where the superscript one is again used to indicate that this is only for the unweighted case where all weights are set to one.</p>
<p>For the weighted case this could be <span class="math inline">\(\mathbf{v}=\left(a_j+w_1', a_j+w_1'+w_2', \dots, a_j+\sum_{k=1}^n w_k' \right)^T\)</span> where <strong><em>W’</em></strong> is a vector containing the weights of the tied units. It is readily apparent that the mean of this vector value will depend on the ordering of the weights. To avoid this, the overall mean of all possible permutations of the weights is calculated. The following formula does just that</p>
<p><span class="math display">\[b_j = \frac{n+1}{2}\bar{w}_j\]</span></p>
<p>where <span class="math inline">\(\bar{w}_j\)</span> is the mean weight of all of the tied units. It is easy to see that when the weights are all one <span class="math inline">\(\bar{w}_j=1\)</span> and <span class="math inline">\(b_j = b_j^1\)</span>. The latter (more general) formula is used for all cases.</p>
<p>After the <strong><em>X</em></strong> and <strong><em>Y</em></strong> vectors are ranked they are plugged into the weighted Pearson correlation coefficient formula shown earlier.</p>
<p>##Formulas for polyserial correlation with and without weights For the polyserial correlation, it is again assumed that there are two continuous variables <strong><em>X</em></strong> and <strong><em>Y</em></strong> that have a bivariate normal distribution.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<p><span class="math display">\[\begin{pmatrix} X \\ Y \end{pmatrix} \sim N \left[ \begin{pmatrix} \mu_x \\ \mu_y \end{pmatrix}, \boldsymbol{\Sigma} \right]\]</span></p>
<p>where <span class="math inline">\(N(\mathbf{A},\boldsymbol{\Sigma})\)</span> is a bivariate normal distribution with mean vector <strong><em>A</em></strong> and covariance matrix <span class="math inline">\(\boldsymbol{\Sigma}\)</span>. For the polyserial correlation, <strong><em>Y</em></strong> is discretized into the random variable <strong><em>M</em></strong> according to</p>
<p><span class="math display">\[m_i= \begin{cases} 1 \quad \mathrm{if}  \theta_2 &lt; y_i &lt; \theta_3 \\ 2 \quad \mathrm{if} \theta_3 &lt; y_i &lt; \theta_4 \\ \vdots \\ t \quad \mathrm{if} \theta_{t+1} &lt; y_i &lt; \theta_{t+2} \end{cases}\]</span></p>
<p>where <span class="math inline">\(\theta\)</span> indicates the cut points used to discretize <strong><em>Y</em></strong> into <strong><em>M</em></strong>, and <span class="math inline">\(t\)</span> is the number of bins. For notational convenience, <span class="math inline">\(\theta_2 \equiv -\infty\)</span> and <span class="math inline">\(\theta_{t+2} \equiv \infty\)</span>.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></p>
<p>To give a concrete example, the following figure shows the density of <strong><em>Y</em></strong> when the cuts points are, for this example, <span class="math inline">\(\theta=\left(-\infty,-2,-0.5,1.6,\infty\right)\)</span>. In this example, any value of <span class="math inline">\(-2 &lt; y_i &lt; -0.5\)</span> would have <span class="math inline">\(m_i=2\)</span>.</p>
<p><strong>Figure 1.</strong> <em>Density of Y for cutpoints <span class="math inline">\(\theta = (-\infty, -2, -0.5, 1.6, \infty\)</span>).</em><br><img src="wCorrFormulas_files/figure-html/theta-1.png" width="672"></p>
<p>Notice that <span class="math inline">\(\mu_y\)</span> is not identified (or is irrelevant) because, for any <span class="math inline">\(a \in \mathbb{R}\)</span>, setting <span class="math inline">\(\tilde{\mu}_y = \mu_y + a\)</span> and <span class="math inline">\(\tilde{\boldsymbol{\theta}}=\boldsymbol{\theta} + a\)</span> lead to exactly the same values of <span class="math inline">\(\mathbf{M}\)</span> and so one of the two must be arbitrarily assigned. A convenient decision is to decide <span class="math inline">\(\mu_y \equiv 0\)</span>. A similar argument holds for <span class="math inline">\(\sigma_y\)</span> so that <span class="math inline">\(\sigma_y \equiv 1\)</span>.</p>
<p>For <strong><em>X</em></strong>, Cox (1974) observes that the MLE mean and standard deviation of <strong><em>X</em></strong> are simply the average and (population) standard deviation of the data and do not depend on the other parameters.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> This can be taken advantage of by defining <span class="math inline">\(z\)</span> to be the standardized score of <span class="math inline">\(x\)</span> so that <span class="math inline">\(z \equiv \frac{x- \bar{x}}{ \hat\sigma_x}\)</span>.</p>
<p>Combining these simplifications, the probability of any given <span class="math inline">\(x_i\)</span>, <span class="math inline">\(m_i\)</span> pair is</p>
<p><span class="math display">\[\mathrm{Pr}\left( \rho=r, \boldsymbol{\Theta}=\boldsymbol{\theta} ; Z=z_i, M=m_i \right) = \phi(z_i) \int_{\theta_{m_i+1}}^{\theta_{m_i+2}} \!\!\!\!\!\!\!\!\!\!\!\!  f(y|Z=z_i,\rho=r)dy\]</span></p>
<p>where <span class="math inline">\(\mathrm{Pr}\left( \rho=r, \boldsymbol{\Theta}=\boldsymbol{\theta}; Z=z_i, M=m_i \right)\)</span> is the probability of the event <span class="math inline">\(\rho=r\)</span> and the cuts points are <span class="math inline">\(\boldsymbol{\theta}\)</span>, given the <span class="math inline">\(i\)</span>th data point <span class="math inline">\(z_i\)</span> and <span class="math inline">\(m_i\)</span>; <span class="math inline">\(\phi(\cdot)\)</span> is the standard normal; and <span class="math inline">\(f(Y|Z,\rho)\)</span> is the distribution of <strong><em>Y</em></strong> conditional on <strong><em>Z</em></strong> and <span class="math inline">\(\rho\)</span>. Because <strong><em>Y</em></strong> and <strong><em>Z</em></strong> are jointly normally distributed (by assumption) <span class="math display">\[f(Y|Z=z_i,\rho=r) =N\left(\mu_y + \frac{\sigma_y}{\sigma_z}r(z_i-\mu_z), (1-r^2){\sigma_y}^2 \right)\]</span> because both <strong><em>Z</em></strong> and <strong><em>Y</em></strong> are standard normals <span class="math display">\[f(y|Z=z_i,\rho=r) =N\left(r \cdot z_i, (1-r^2) \right)\]</span> Noticing that <span class="math inline">\(\frac{y-r\cdot z}{\sqrt{1-r^2}}\)</span> has a standard normal distribution <span class="math display">\[\mathrm{Pr}\left( \rho=r, \boldsymbol{\Theta}=\boldsymbol{\theta} ; Z=z_i, M=m_i \right) = \phi(z_i) \left[ \Phi\left( \frac{\theta_{m_i+2} - r \cdot z_i}{\sqrt{1-r^2}} \right) - \Phi \left( \frac{\theta_{m_i+1} - r \cdot z_i}{\sqrt{1-r^2}} \right) \right]\]</span></p>
<p>where <span class="math inline">\(\Phi(\cdot)\)</span> is the standard normal cumulative density function. Using the above probability function as an objective, the log-likelihood is then maximized. <span class="math display">\[\ell(\rho=r, \boldsymbol{\Theta}=\boldsymbol{\theta};\mathbf{Z}=\mathbf{z},\mathbf{M}=\mathbf{m}) = \sum_{i=1}^n w_i \ln\left[ \mathrm{Pr}\left( \rho=r, \boldsymbol{\Theta}=\boldsymbol{\theta} ; Z=z_i, M=m_i \right) \right]\]</span> where <span class="math inline">\(w_i\)</span> is the weight of the <span class="math inline">\(i^{th}\)</span> members of the vectors <strong><em>Z</em></strong> and <strong><em>Y</em></strong>. For the unweighted case, all of the weights are set to one.</p>
<p>The value of the nuisance parameter <span class="math inline">\(\boldsymbol{\theta}\)</span> is chosen to be</p>
<p><span class="math display">\[\hat{\theta}_{j+2} = \Phi^{-1}(n/N)\]</span></p>
<p>where <span class="math inline">\(n\)</span> is the number of values to the left of the <span class="math inline">\(j\)</span>th cut point (<span class="math inline">\(\theta_{j+2}\)</span> value) and <span class="math inline">\(N\)</span> is the number of data points overall. Here two is added to <span class="math inline">\(j\)</span> to make the indexing of <span class="math inline">\(\theta\)</span> agree with Cox (1974) as noted before. For the weighted cause <span class="math inline">\(n\)</span> is replaced by the sum of the weights to the left of the <span class="math inline">\(j\)</span>th cut point and <span class="math inline">\(N\)</span> is replaced by the total weight of all units</p>
<p><span class="math display">\[\hat{\theta}_{j+2} = \Phi^{-1}\left( \frac{\sum_{i=1}^N w_i \mathbf{1}(m_i &lt; j) }{\sum_{i=1}^N w_i} \right)\]</span></p>
<p>where <span class="math inline">\(\mathbf{1}\)</span> is the indicator function that is 1 when the condition is true and 0 otherwise.</p>
<p>###Computation of polyserial correlation For the polyserial, derivatives of <span class="math inline">\(\ell\)</span> can be written down but are not readily computed. When the <code>ML</code> argument is set to <code>FALSE</code> (the default), a one dimensional optimization of <span class="math inline">\(\rho\)</span> is calculated using the <code>optimize</code> function in the <code>stats</code> package and the values of <span class="math inline">\(\boldsymbol{\theta}\)</span> from the previous paragraph. When the <code>ML</code> argument is set to <code>TRUE</code>, a multi-dimensional optimization is done for <span class="math inline">\(\rho\)</span> and <span class="math inline">\(\boldsymbol{\theta}\)</span> using the <code>bobyqa</code> function in the <code>minqa</code> package. See the <em>wCorr Arguments</em> vignette for a comparison of these two methods.</p>
<p>Because the numerical optimization is not perfect when the correlation is in a boundary condition (<span class="math inline">\(\rho \in \{-1,1\}\)</span>), a check for perfect correlation is performed before the above optimization by simply examining if the values of <strong><em>X</em></strong> and <strong><em>M</em></strong> have agreeing order (or opposite but agreeing order) and then the MLE correlation of 1 (or -1) is returned.</p>
<p>##Methodology for polychoric correlation with and without weights</p>
<p>Similar to the polyserial correlation, the polychoric correlation is a simple case of two continuous variables <strong><em>X</em></strong> and <strong><em>Y</em></strong> that have a bivariate normal distribution. In the case of the polyserial correlation the continuous (latent) variable <strong><em>Y</em></strong> was observed as a discretized variable <strong><em>M</em></strong>. For the polychoric correlation, this is again true but now the continuous (latent) variable <strong><em>X</em></strong> is observed as a discrete variable <strong><em>P</em></strong> according to</p>
<p><span class="math display">\[p_i= \begin{cases} 1 \quad \mathrm{if}  \theta'_2 &lt; x_i &lt; \theta'_3 \\ 2 \quad \mathrm{if} \theta'_3 &lt; x_i &lt; \theta'_4 \\ \vdots \\ t \quad \mathrm{if} \theta'_{t'+1} &lt; x_i &lt; \theta'_{t'+2} \end{cases}\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{\theta}\)</span> remains the cut points for the distibution defining the transformation of <strong><em>Y</em></strong> to <strong><em>M</em></strong>, <span class="math inline">\(\boldsymbol{\theta}'\)</span> is the cut points for the transformation from <strong><em>X</em></strong> to <strong><em>P</em></strong>, and <span class="math inline">\(t'\)</span> is the number of bins for <strong><em>P</em></strong>. Similar to <span class="math inline">\(\boldsymbol{\theta}\)</span>, <span class="math inline">\(\boldsymbol{\theta}'\)</span> has <span class="math inline">\(\theta'_2 \equiv -\infty\)</span> and <span class="math inline">\(\theta'_{t'+2} \equiv \infty\)</span>.</p>
<p>As in the polyserial correlation, <span class="math inline">\(\mu_y\)</span> is not identified (or is irrelevant) because, for any <span class="math inline">\(a \in \mathbb{R}\)</span>, setting <span class="math inline">\(\tilde{\mu}_y = \mu_y + a\)</span> and <span class="math inline">\(\tilde{\boldsymbol{\theta}}=\boldsymbol{\theta} + a\)</span> lead to exactly the same values of <span class="math inline">\(\mathbf{M}\)</span> and so one of the two must be arbitrarily assigned. The same is true for <span class="math inline">\(\mu_x\)</span>. A convenient decision is to decide <span class="math inline">\(\mu_y = \mu_x \equiv 0\)</span>. A similar argument holds for <span class="math inline">\(\sigma_y\)</span> and <span class="math inline">\(\sigma_x\)</span> so that <span class="math inline">\(\sigma_y = \sigma_x \equiv 1\)</span></p>
<p>Then the probability of any given <span class="math inline">\(m_i\)</span>, <span class="math inline">\(p_i\)</span> pair is</p>
<p><span class="math display">\[\mathrm{Pr}\left( \rho=r, \boldsymbol{\Theta}=\boldsymbol{\theta}, \boldsymbol{\Theta}'=\boldsymbol{\theta}' ; P=p_i, M=m_i \right) = \int_{\theta'_{p_i+1}}^{\theta'_{p_i+2}}  \int_{\theta_{m_i+1}}^{\theta_{m_i+2}} \!\!\!\!\!\!\!\!\!\!\!\!  f(x,y|\rho=r)dydx\]</span></p>
<p>where <span class="math inline">\(\rho\)</span> is the correlation coefficient.</p>
<p>Using this function as an objective, the log-likelihood is then maximized. <span class="math display">\[\ell(\rho=r, \boldsymbol{\Theta}=\boldsymbol{\theta}, \boldsymbol{\Theta}'=\boldsymbol{\theta}';\mathbf{P}=\mathbf{p},\mathbf{M}=\mathbf{m}) = \sum_{i=1}^n w_i \ln\left[\mathrm{Pr}\left( \rho=r, \boldsymbol{\Theta}=\boldsymbol{\theta}, \boldsymbol{\Theta}'=\boldsymbol{\theta}' ; P=p_i, M=m_i \right) \right] \]</span></p>
<p>This is the weighted log-likelihood function. For the unweighted case all of the weights are set to one.</p>
<p>###Computation of polychoric correlation This again mirrors the treatment of the polyserial. The derivatives of <span class="math inline">\(\ell\)</span> for the polychoric can be written down but are not readily computed. When the <code>ML</code> argument is set to <code>FALSE</code> (the default), a one dimensional optimization of <span class="math inline">\(\rho\)</span> is calculated using the <code>optimize</code> function from the <code>stats</code> package and values of <span class="math inline">\(\boldsymbol{\theta}\)</span> and <span class="math inline">\(\boldsymbol{\theta}'\)</span> are computed using the last equation in the section titled, “Formulas for polyserial correlation with and without weights”. When the <code>ML</code> argument is set to <code>TRUE</code> a multi-dimensional optimization is done for <span class="math inline">\(\rho\)</span>, <span class="math inline">\(\boldsymbol{\theta}\)</span>, and <span class="math inline">\(\boldsymbol{\theta}'\)</span> using the <code>bobyqa</code> function in the <code>minqa</code> package. See the <em>wCorr Arguments</em> vignette for a comparison of these two methods.</p>
<p>Because the optimization is not perfect when the correlation is in a boundary condition (<span class="math inline">\(\rho \in \{-1,1\}\)</span>), a check for perfect correlation is performed before the above optimization by simply examining if the values of <strong><em>P</em></strong> and <strong><em>M</em></strong> have a Goodman-Kruskal correlation coefficient of -1 or 1. When this is the case, the MLE of -1 or 1, respectively, is returned.</p>
<p>#Simulation evidence on the correctness of the estimating methods</p>
<p>It is easy to prove the consistency of the <span class="math inline">\(\boldsymbol{\theta}\)</span> for the polyserial correlation and <span class="math inline">\(\boldsymbol{\theta}\)</span> and <span class="math inline">\(\boldsymbol{\theta}'\)</span> for the polychoric correlation using the non-ML case. Similarly, for <span class="math inline">\(\rho\)</span>, because it is an MLE that can be obtained by taking a derivative and setting it equal to zero, the results are asymptotically unbiased and obtain the Cramer-Rao lower bound.</p>
<p>This does not speak to the small sample properties of these correlation coefficients. Previous work has described their properties by simulation; and that tradition is continued below.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a></p>
</div>
<div id="simulation-study-of-unweighted-correlations" class="section level2">
<h2 class="hasAnchor">
<a href="#simulation-study-of-unweighted-correlations" class="anchor"></a>Simulation study of unweighted correlations</h2>
<p>In what follows, when the exact method of selecting a parameter (such as <span class="math inline">\(n\)</span>) is not noted in the above descriptions it is described as part of each simulation.</p>
<p>Across a number of iterations (the exact number of times will be stated for each simulation), the following procedure is used:</p>
<ul>
<li>select a true Pearson correlation coefficient <span class="math inline">\(\rho\)</span>;</li>
<li>select the number of observations <span class="math inline">\(n\)</span>;</li>
<li>generate <strong><em>X</em></strong> and <strong><em>Y</em></strong> to be bivariate normally distributed using a pseudo-Random Number Generator (RNG);</li>
<li>using a pseudo-RNG, select the number of bins for <strong><em>M</em></strong> and <strong><em>P</em></strong> (<span class="math inline">\(t\)</span> and <span class="math inline">\(t'\)</span>) independantly from the set {2, 3, 4, 5};<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>
</li>
<li>select the bin boundaries for <strong><em>M</em></strong> and <strong><em>P</em></strong> (<span class="math inline">\(\boldsymbol{\theta}\)</span> and <span class="math inline">\(\boldsymbol{\theta}'\)</span>) by sorting the results of <span class="math inline">\((t-1)\)</span> and <span class="math inline">\((t'-1)\)</span> draws, respectively, from a normal distribution using a pseudo-RNG;</li>
<li>confirm that at least 2 levels of each of <strong><em>M</em></strong> and <strong><em>P</em></strong> are occupied (if not, return to previous step); and</li>
<li>calculate and record relevant statistics.</li>
</ul>
</div>
<div id="bias-and-rmse-of-the-unweighted-correlations" class="section level2">
<h2 class="hasAnchor">
<a href="#bias-and-rmse-of-the-unweighted-correlations" class="anchor"></a>Bias, and RMSE of the unweighted correlations</h2>
<p>This sections shows the bias of the correlations as a function of the true correlation coefficient, <span class="math inline">\(\rho\)</span>. To that end, a simulation was done at each level of the cartesian product of <span class="math inline">\(\rho \in \left( -0.99, -0.95, -0.90, -0.85, ..., 0.95, 0.99 \right)\)</span>, and <span class="math inline">\(n \in \{10, 100, 1000\}\)</span>. For precision, each level of <span class="math inline">\(\rho\)</span> and <span class="math inline">\(n\)</span> was run fifty times. The bias is the mean difference between the true correlation coefficient (<span class="math inline">\(\rho_i\)</span>) and estimate correlation coefficient (<span class="math inline">\(r_i\)</span>). The RMSE is the square root of the mean squared error.</p>
<p><span class="math display">\[\mathrm{RMSE}= \sqrt{ \frac{1}{n} \sum_{i=1}^n \left( r_i - \rho_i \right)^2 }\]</span></p>
<p>And the bias is given by</p>
<p><span class="math display">\[bias=\frac{1}{n}\sum_{i=1}^n \left(r_i - \rho_i \right)\]</span></p>
<p>Figure 2 shows the bias as a function of the true correlation <span class="math inline">\(\rho\)</span>. Only the polyserial shows no bias at any level of <span class="math inline">\(n\)</span>, shown by no clear deviation from 0 at any level of <span class="math inline">\(\rho\)</span>. For the Pearson correlation there is bias when <span class="math inline">\(n=10\)</span> that is not present when <span class="math inline">\(n=100\)</span> or 1,000. This is a well known property of the estimator.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> Similarly, the polychoric shows bias when <span class="math inline">\(n=10\)</span>.</p>
<p>The Spearman correlation shows bias at all of the tested levels of <span class="math inline">\(n\)</span>. The bias is zero when the true correlation is 1, 0, or -1; is positive when <span class="math inline">\(\rho\)</span> is below 0 (negative correlation); and is negative when <span class="math inline">\(\rho\)</span> is above 0 (positive correlation). In this section, the Spearman correlation coefficient is compared with the true Pearson correlation coefficient. When this is done, the bias is expected because the Spearman correlation is not intended to recover a Pearson type correlation coefficient; it is designed to measure a separate quantity.</p>
<p><strong>Figure 2.</strong> <em>Bias Versus <span class="math inline">\(\rho\)</span> for Unweighted Correlations.</em><br><img src="wCorrFormulas_files/figure-html/bias%20Versus%20rho-1.png" width="672"></p>
<div style="page-break-after: always;"></div>
<p>Figure 3 shows the RMSE as a function of <span class="math inline">\(\rho\)</span>. All of the correlation coefficients have a uniform RMSE as a function of <span class="math inline">\(\rho\)</span> near <span class="math inline">\(\rho=0\)</span> that decreases near <span class="math inline">\(|\rho|=1\)</span>. All plots also show a decrease in RMSE as <span class="math inline">\(n\)</span> increases. This plot shows that there is no appreciable RMSE differences as a functions of <span class="math inline">\(\rho\)</span>. In addition, it show that our attention to the MLE correlation of -1 or 1 at edge cases did not make the RMSE much worse in the neighborhood of the edges (<span class="math inline">\(|\rho| \sim 1\)</span>).</p>
<p><strong>Figure 3.</strong> <em>Root Mean Square Error Versus <span class="math inline">\(\rho\)</span> for Unweighted Correlations.</em><br><img src="wCorrFormulas_files/figure-html/rmse%20Versus%20rho-1.png" width="672"></p>
<div id="consistency-of-the-correlations" class="section level4">
<h4 class="hasAnchor">
<a href="#consistency-of-the-correlations" class="anchor"></a>Consistency of the correlations</h4>
<p>Figure 4 shows the RMSE as a function of <span class="math inline">\(n\)</span>. The purpose of this plot is not to show an individual value but to show that the estimator is consistent. The plot shows a slope of about <span class="math inline">\(-\frac{1}{2}\)</span> for the Pearson, polychoric, and polyserial correlations. This is consistent with the expected first order convergence for each correlation coefficient under the assumptions of this simulation. Results for the Spearman also show approximate first order convergence but the slope increases slightly as <span class="math inline">\(n\)</span> increases. Again, the Spearman is not estimating the same quantity as the Pearson and so is expected to diverge.</p>
<p>The plot also shows that the RMSE is less than 0.1 for all methods when <span class="math inline">\(n&gt;100\)</span>.</p>
<p><strong>Figure 4.</strong> <em>Root Mean Square Error Versus sample size for Unweighted Correlations.</em><br><img src="wCorrFormulas_files/figure-html/rmse%20Versus%20n-1.png" width="672"></p>
</div>
<div id="computing-time" class="section level4">
<h4 class="hasAnchor">
<a href="#computing-time" class="anchor"></a>Computing Time</h4>
<p>Figure 5 shows the mean time (in seconds) to compute a single correlation coefficient as a function of <span class="math inline">\(\rho\)</span> by <span class="math inline">\(n\)</span> size. The plot shows linearly rising computation times with slopes of about one. This is consistent with a linear computation cost. Using Big O notation, the computation cost is, in the range shown, O(<span class="math inline">\(n\)</span>). The slope of the Spearman is slightly faster and the algorithm has a O(<span class="math inline">\(n \mathrm{lg}(n)\)</span>) sort involved, so this is, again, expected.</p>
<p><strong>Figure 5.</strong> <em>Computation time.</em><br><img src="wCorrFormulas_files/figure-html/time%20Versus%20n-1.png" width="672"></p>
</div>
</div>
<div id="simulation-study-of-weighted-correlations" class="section level2">
<h2 class="hasAnchor">
<a href="#simulation-study-of-weighted-correlations" class="anchor"></a>Simulation study of weighted correlations</h2>
<p>When complex sampling (other than simple random sampling with replacement) is used, unweighted correlations may or may not be consistent. In this section the consistency of the weighted coefficients is examined.</p>
<p>When generating simulated data, decisions about the generating functions have to be made. These decisions affect how the results are interpreted. For the weighted case, if these decisions lead to something about the higher weight cases being different from the lower weight cases then the test will be more informative about the role of weights. Thus, while it is not reasonable to always assume that there is a difference between the high and low weight cases, the assumption (used in the simulations below) that there is an association between weights and the correlation coefficients serves as a more robust test of the methods in this package.</p>
<p>##Results of weighted correlation simulations</p>
<p>Simulations are carried out in the same fashion as previously described but include a few extra steps to accommodate weights. The following changes were made:</p>
<ul>
<li>Weights are assigned according to <span class="math inline">\(w_i = (x-y)^2 + 1\)</span>, and the probability of inclusion in the sample was then <span class="math inline">\(Pr_i = \frac{1}{w_i}\)</span>.</li>
<li>For each unit, a uniformly distributed random number was drawn. When that value was less than the probability of inclusion (<span class="math inline">\(Pr_i\)</span>), the unit was included.</li>
</ul>
<p>Units were generated until <span class="math inline">\(n\)</span> units were in the sample.</p>
<p>Two simulations were run. The first shows the mean absolute deviation (MAD)</p>
<p><span class="math display">\[MAD=\frac{1}{n}\sum_{i=1}^n |r_i - \rho_i|\]</span></p>
<p>as a function of <span class="math inline">\(\rho\)</span> and was run for <span class="math inline">\(n=100\)</span> and <span class="math inline">\(\rho \in \left( -0.99, -0.95, -0.90, -0.85, ..., 0.95, 0.99 \right)\)</span>, with 100 iterations run for each value of <span class="math inline">\(\rho\)</span>.</p>
<p>The following plot shows the MAD for the weighted and unweighted results as a function of <span class="math inline">\(\rho\)</span> when <span class="math inline">\(n=100\)</span>. This shows that for values of <span class="math inline">\(\rho\)</span> near zero, under our simulation assumptions (for all but the Spearman correlation) the weighted correlation performs better than (that is, has lower MAD than) the unweighted correlation for all correlation coefficients. Over the entire range, the difference between the two is never such that the unweighted has a lower MAD. Thus, under the simulated conditions at least, the weighted correlation has lower or approximately equal MAD for every value of the true correlation coefficient (<span class="math inline">\(\rho\)</span>).</p>
<p><strong>Figure 6.</strong> <em>Mean Absolute Deviation Versus <span class="math inline">\(\rho\)</span> (Weighted).</em><br><img src="wCorrFormulas_files/figure-html/wgt%20Versus%20rho%20plot-1.png" width="672"></p>
<p>The second simulation (shown in Figure 7) used the same values of <span class="math inline">\(\rho\)</span> and used <span class="math inline">\(n \in \{10, 100, 1000, 10000 \}\)</span> and shows how RMSE and sample size are related. In particular, it shows first-order convergence of the weighted Pearson, polyserial, and polychoric correlation coefficient.</p>
<p>For the previous plots the calculated Spearman correlation coefficient was compared to the generating Pearson correlation coefficient. For this plot only, the Spearman correlation coefficient to the true Spearman correlation coefficient. This is because the Spearman coefficient is not attempting to estimate the Pearson correlation. To do this the simulation is modified slightly. A population of data is generated and the true Spearman correlation coefficient then is calculated as the population coefficient.<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a> Then, a sample from the population with varying probability as described in the weighted simulation section is used to calculate sample Spearman correlation coefficient. Then the root mean squared difference between the sample and population coefficients are calculated as with the Pearson–except that the population Spearman correlation coefficient is used in place of the Pearson correlation coefficient (<span class="math inline">\(\rho\)</span>).</p>
<p>Thus, the results in Figure 7 show that, when compared to the true Spearman correlation coefficient, the weighted Spearman correlation coefficient is consistent.</p>
<p>In all cases the RMSE is lower for the weighted than the unweighted. Again, the fact that the simulations show that the unweighted correlation coefficient is not consistent does not imply that it will always be that way–only that this is possible for these coefficients to not be consistent.</p>
<p><strong>Figure 7.</strong> <em>Root Mean Square Error Versus <span class="math inline">\(\rho\)</span> (Polyserial, Pearson, Polychoric panels) or Population Spearman correlation coefficient (Spearman panel) for Weighted Correlations</em><br><img src="wCorrFormulas_files/figure-html/wgt%20v%20n%20plot-1.png" width="672"></p>
<p>#Conclusion Overall the simulations show first order convergence for each unweighted correlation coefficient with an approximately linear computation cost. Further, under our simulation assumptions, the weighted correlation performs better than (has lower MAD or RMSE than) the unweighted correlation for all correlation coefficients.</p>
<p>We show the first order convergence of the weighted Pearson, polyserial, and polychoric correlation coefficient. The Spearman is shown to not consistently estimate the population Pearson correlation coefficient but is shown to consistently estimate the population Spearman correlation coefficient–under the assumptions of our simulation.</p>
</div>
</div>
<div id="appendix-proof-of-consistency-of-horvitz-thompson-ht-estimator-of-a-mean" class="section level1">
<h1 class="hasAnchor">
<a href="#appendix-proof-of-consistency-of-horvitz-thompson-ht-estimator-of-a-mean" class="anchor"></a>Appendix Proof of consistency of Horvitz-Thompson (HT) estimator of a mean</h1>
<p>An HT estimator of a sum takes the form <span class="math display">\[\hat{Y} = \sum_{i=1}^n \frac{1}{\pi_i} y_i\]</span> where there are <span class="math inline">\(n\)</span> sampled units from a population of <span class="math inline">\(N\)</span> units, each unit has a value <span class="math inline">\(y\in R\)</span>, each unit is sampled with probability <span class="math inline">\(\pi_i\)</span>, and <span class="math inline">\(\hat{Y}\)</span> is the estimated of <span class="math inline">\(Y\)</span> in a population. Here there is no assumed covariance between sampling of unit <span class="math inline">\(i\)</span> and unit <span class="math inline">\(j\)</span>, and the inverse probability is also the unit’s weight <span class="math inline">\(w_i\)</span>, so that an alternative specification of (1) is <span class="math display">\[\hat{Y} = \sum_{i=1}^n w_i y_i \ .\]</span></p>
</div>
<div class="footnotes">
<hr>
<ol>
<li id="fn1"><p>The estimation procedure used by the wCorr package for the polyserial is based on the likelihood function in Cox, N. R. (1974), “Estimation of the Correlation between a Continuous and a Discrete Variable.” <em>Biometrics</em>, <strong>30</strong> (1), pp 171-178. The likelihood function for polychoric is from Olsson, U. (1979) “Maximum Likelihood Estimation of the Polychoric Correlation Coefficient.” <em>Psyhometrika</em>, <strong>44</strong> (4), pp 443-460. The likelihood used for Pearson and Spearman is written down in many places. One is the “correlate” function in Stata Corp, Stata Statistical Software: Release 8. College Station, TX: Stata Corp LP, 2003.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Sample weights are comparable to <code>pweight</code> in Stata.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>See the “correlate” function in Stata Corp, Stata Statistical Software: Release 8. College Station, TX: Stata Corp LP, 2003.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>For a more complete treatment of the polyserial correlation, see Cox, N. R., “Estimation of the Correlation between a Continuous and a Discrete Variable” <em>Biometrics</em>, <strong>50</strong> (March), 171-187, 1974.<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>The indexing is somewhat odd to be consistent with Cox (1974). Nevertheless, this treatment does not use the Cox definition of <span class="math inline">\(\theta_0\)</span>, <span class="math inline">\(\theta_1\)</span> or <span class="math inline">\(\theta_2\)</span> which are either not estimated (as is the case for <span class="math inline">\(\theta_0\)</span>, and <span class="math inline">\(\theta_1\)</span>) or are reappropriated (as is the case for <span class="math inline">\(\theta_2\)</span>). Cox calls the correlation coefficient <span class="math inline">\(\theta_2\)</span> while this document uses <span class="math inline">\(\rho\)</span> and uses <span class="math inline">\(\theta_2\)</span> to store <span class="math inline">\(-\infty\)</span> as a convenience so that the vector <span class="math inline">\(\boldsymbol{\theta}\)</span> includes the (infinite) bounds as well as the interior points.<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>The population standard deviation is used because it is the MLE for the standard deviation. Notice that, while the sample variance is an unbiased estimator of the variance and the population variance is not an unbaised estimator of the variance, they are very similar and the variance is also a nuisance parameter, not a parameter of interest when finding the correlation.<a href="#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>See, for example, the introduction to Rigdon, E. E. and Ferguson C. E., “The Performance of the Polychoric Correlation Coefficient and Selected Fitting Functions in Confirmatory Factor Analysis With Ordinal Data” <em>Journal of Marketing Research</em> <strong>28</strong> (4), pp. 491-497.<a href="#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>This means that the simulation uses discrete ordinal variables (<strong><em>M</em></strong> and <strong><em>P</em></strong>) that have 2, 3, 4, or 5 discrete levels. Note that the number of levels in <strong><em>M</em></strong> and <strong><em>P</em></strong> are chosen independently so that one could be 2 while the other is 5 (or any other possible combination).<a href="#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p>see, for example, Olkin I. and Pratt, J. W. (1958), Unbiased Estimation of Certain Correlation Coefficients. <em>Annals of Mathematical Statistics</em>, <em>29</em> (1), 201–211.<a href="#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>The R <code>stats</code> package <code>cor</code> function is used to calculate the population Spearman correlation coefficient; this results in an unweighted coefficient, which is appropriate for the population parameter.<a href="#fnref10" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Paul Bailey.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
